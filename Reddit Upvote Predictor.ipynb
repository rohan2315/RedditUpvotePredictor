{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.stem.lancaster import LancasterStemmer  \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850359, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_data=data[data['subreddit']=='AskReddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gilded</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>downs</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>...</th>\n",
       "      <th>body</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>name</th>\n",
       "      <th>score_hidden</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>archived</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>removal_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o</td>\n",
       "      <td>t3_7k903</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>ermine</td>\n",
       "      <td>1</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>Ok. Here's what you do. Get some speaker wire ...</td>\n",
       "      <td>1428217153</td>\n",
       "      <td>t3_7k903</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_o</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580158</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t3_7k377</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>movzx</td>\n",
       "      <td>3</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>lol yeah you're right! so hilarious!</td>\n",
       "      <td>1428217153</td>\n",
       "      <td>t1_c06vnj0</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_t</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580220</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1h</td>\n",
       "      <td>t3_7k8xe</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>robrobrobot</td>\n",
       "      <td>5</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>Yeah, I've contemplated that quite a bit as we...</td>\n",
       "      <td>1428217153</td>\n",
       "      <td>t1_c06vwnq</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_1h</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580347</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>t3_7k92p</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>Let us plan this one :).......</td>\n",
       "      <td>1428217153</td>\n",
       "      <td>t1_c06vwn9</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_25</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580422</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>t3_7k7ff</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>kenlubin</td>\n",
       "      <td>1</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>which?</td>\n",
       "      <td>1428217154</td>\n",
       "      <td>t3_7k7ff</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_32</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580531</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3m</td>\n",
       "      <td>t3_7k7vs</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>krispykrackers</td>\n",
       "      <td>4</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>♥qghy2♥\\n\\n\\nHe's had a lot of reddit love tod...</td>\n",
       "      <td>1428217154</td>\n",
       "      <td>t3_7k7vs</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_3m</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580640</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4g</td>\n",
       "      <td>t3_7k3z1</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>chibikiba</td>\n",
       "      <td>1</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>We already have the shoes.</td>\n",
       "      <td>1428217154</td>\n",
       "      <td>t3_7k3z1</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_4g</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4r</td>\n",
       "      <td>t3_7k90i</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>marydaze</td>\n",
       "      <td>-1</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>cool, cool</td>\n",
       "      <td>1428217154</td>\n",
       "      <td>t3_7k90i</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_4r</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580821</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4v</td>\n",
       "      <td>t3_7k7vs</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>krispykrackers</td>\n",
       "      <td>3</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>You do know he abandoned us, right?  I mean, I...</td>\n",
       "      <td>1428217154</td>\n",
       "      <td>t1_c06vvdm</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_4v</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580830</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>t3_7k377</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>ermine</td>\n",
       "      <td>2</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>They don't consider you competent. You are sim...</td>\n",
       "      <td>1428217154</td>\n",
       "      <td>t3_7k377</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_55</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580843</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  gilded author_flair_css_class  id   link_id  downs  \\\n",
       "21           21       0                    NaN   o  t3_7k903      0   \n",
       "26           26       0                    NaN   t  t3_7k377      0   \n",
       "50           50       0                    NaN  1h  t3_7k8xe      0   \n",
       "74           74       0                    NaN  25  t3_7k92p      0   \n",
       "107         107       0                    NaN  32  t3_7k7ff      0   \n",
       "127         127       0                    NaN  3m  t3_7k7vs      0   \n",
       "155         155       0                    NaN  4g  t3_7k3z1      0   \n",
       "166         166       0                    NaN  4r  t3_7k90i      0   \n",
       "170         170       0                    NaN  4v  t3_7k7vs      0   \n",
       "180         180       0                    NaN  55  t3_7k377      0   \n",
       "\n",
       "     subreddit          author  score subreddit_id  ...  \\\n",
       "21   AskReddit          ermine      1     t5_2qh1i  ...   \n",
       "26   AskReddit           movzx      3     t5_2qh1i  ...   \n",
       "50   AskReddit     robrobrobot      5     t5_2qh1i  ...   \n",
       "74   AskReddit       [deleted]      1     t5_2qh1i  ...   \n",
       "107  AskReddit        kenlubin      1     t5_2qh1i  ...   \n",
       "127  AskReddit  krispykrackers      4     t5_2qh1i  ...   \n",
       "155  AskReddit       chibikiba      1     t5_2qh1i  ...   \n",
       "166  AskReddit        marydaze     -1     t5_2qh1i  ...   \n",
       "170  AskReddit  krispykrackers      3     t5_2qh1i  ...   \n",
       "180  AskReddit          ermine      2     t5_2qh1i  ...   \n",
       "\n",
       "                                                  body  retrieved_on  \\\n",
       "21   Ok. Here's what you do. Get some speaker wire ...    1428217153   \n",
       "26                lol yeah you're right! so hilarious!    1428217153   \n",
       "50   Yeah, I've contemplated that quite a bit as we...    1428217153   \n",
       "74                      Let us plan this one :).......    1428217153   \n",
       "107                                             which?    1428217154   \n",
       "127  ♥qghy2♥\\n\\n\\nHe's had a lot of reddit love tod...    1428217154   \n",
       "155                         We already have the shoes.    1428217154   \n",
       "166                                         cool, cool    1428217154   \n",
       "170  You do know he abandoned us, right?  I mean, I...    1428217154   \n",
       "180  They don't consider you competent. You are sim...    1428217154   \n",
       "\n",
       "      parent_id controversiality   name score_hidden  distinguished archived  \\\n",
       "21     t3_7k903                0   t1_o        False            NaN     True   \n",
       "26   t1_c06vnj0                0   t1_t        False            NaN     True   \n",
       "50   t1_c06vwnq                0  t1_1h        False            NaN     True   \n",
       "74   t1_c06vwn9                0  t1_25        False            NaN     True   \n",
       "107    t3_7k7ff                0  t1_32        False            NaN     True   \n",
       "127    t3_7k7vs                0  t1_3m        False            NaN     True   \n",
       "155    t3_7k3z1                0  t1_4g        False            NaN     True   \n",
       "166    t3_7k90i                0  t1_4r        False            NaN     True   \n",
       "170  t1_c06vvdm                0  t1_4v        False            NaN     True   \n",
       "180    t3_7k377                0  t1_55        False            NaN     True   \n",
       "\n",
       "     created_utc removal_reason  \n",
       "21    1229580158            NaN  \n",
       "26    1229580220            NaN  \n",
       "50    1229580347            NaN  \n",
       "74    1229580422            NaN  \n",
       "107   1229580531            NaN  \n",
       "127   1229580640            NaN  \n",
       "155   1229580768            NaN  \n",
       "166   1229580821            NaN  \n",
       "170   1229580830            NaN  \n",
       "180   1229580843            NaN  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_data=ask_data[ask_data['body']!='[deleted]']\n",
    "ask_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55006, 23)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords.words('english') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gilded</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>downs</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>...</th>\n",
       "      <th>body</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>name</th>\n",
       "      <th>score_hidden</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>archived</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>removal_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o</td>\n",
       "      <td>t3_7k903</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>ermine</td>\n",
       "      <td>1</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>ok  here s what you do  get some speaker wire ...</td>\n",
       "      <td>1428217153</td>\n",
       "      <td>t3_7k903</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_o</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580158</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>t3_7k377</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>movzx</td>\n",
       "      <td>3</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>lol yeah you re right  so hilarious</td>\n",
       "      <td>1428217153</td>\n",
       "      <td>t1_c06vnj0</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_t</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580220</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1h</td>\n",
       "      <td>t3_7k8xe</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>robrobrobot</td>\n",
       "      <td>5</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>yeah  i ve contemplated that quite a bit as we...</td>\n",
       "      <td>1428217153</td>\n",
       "      <td>t1_c06vwnq</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_1h</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580347</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>t3_7k92p</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>let us plan this one</td>\n",
       "      <td>1428217153</td>\n",
       "      <td>t1_c06vwn9</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_25</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580422</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>t3_7k7ff</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>kenlubin</td>\n",
       "      <td>1</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>which</td>\n",
       "      <td>1428217154</td>\n",
       "      <td>t3_7k7ff</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_32</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580531</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3m</td>\n",
       "      <td>t3_7k7vs</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>krispykrackers</td>\n",
       "      <td>4</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>he s had a lot of reddit love today  but...</td>\n",
       "      <td>1428217154</td>\n",
       "      <td>t3_7k7vs</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_3m</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580640</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4g</td>\n",
       "      <td>t3_7k3z1</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>chibikiba</td>\n",
       "      <td>1</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>we already have the shoes</td>\n",
       "      <td>1428217154</td>\n",
       "      <td>t3_7k3z1</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_4g</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580768</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4r</td>\n",
       "      <td>t3_7k90i</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>marydaze</td>\n",
       "      <td>-1</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>cool  cool</td>\n",
       "      <td>1428217154</td>\n",
       "      <td>t3_7k90i</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_4r</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580821</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4v</td>\n",
       "      <td>t3_7k7vs</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>krispykrackers</td>\n",
       "      <td>3</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>you do know he abandoned us  right   i mean  i...</td>\n",
       "      <td>1428217154</td>\n",
       "      <td>t1_c06vvdm</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_4v</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580830</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>t3_7k377</td>\n",
       "      <td>0</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>ermine</td>\n",
       "      <td>2</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>...</td>\n",
       "      <td>they don t consider you competent  you are sim...</td>\n",
       "      <td>1428217154</td>\n",
       "      <td>t3_7k377</td>\n",
       "      <td>0</td>\n",
       "      <td>t1_55</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1229580843</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  gilded author_flair_css_class  id   link_id  downs  \\\n",
       "21           21       0                    NaN   o  t3_7k903      0   \n",
       "26           26       0                    NaN   t  t3_7k377      0   \n",
       "50           50       0                    NaN  1h  t3_7k8xe      0   \n",
       "74           74       0                    NaN  25  t3_7k92p      0   \n",
       "107         107       0                    NaN  32  t3_7k7ff      0   \n",
       "127         127       0                    NaN  3m  t3_7k7vs      0   \n",
       "155         155       0                    NaN  4g  t3_7k3z1      0   \n",
       "166         166       0                    NaN  4r  t3_7k90i      0   \n",
       "170         170       0                    NaN  4v  t3_7k7vs      0   \n",
       "180         180       0                    NaN  55  t3_7k377      0   \n",
       "\n",
       "     subreddit          author  score subreddit_id  ...  \\\n",
       "21   AskReddit          ermine      1     t5_2qh1i  ...   \n",
       "26   AskReddit           movzx      3     t5_2qh1i  ...   \n",
       "50   AskReddit     robrobrobot      5     t5_2qh1i  ...   \n",
       "74   AskReddit       [deleted]      1     t5_2qh1i  ...   \n",
       "107  AskReddit        kenlubin      1     t5_2qh1i  ...   \n",
       "127  AskReddit  krispykrackers      4     t5_2qh1i  ...   \n",
       "155  AskReddit       chibikiba      1     t5_2qh1i  ...   \n",
       "166  AskReddit        marydaze     -1     t5_2qh1i  ...   \n",
       "170  AskReddit  krispykrackers      3     t5_2qh1i  ...   \n",
       "180  AskReddit          ermine      2     t5_2qh1i  ...   \n",
       "\n",
       "                                                  body  retrieved_on  \\\n",
       "21   ok  here s what you do  get some speaker wire ...    1428217153   \n",
       "26                lol yeah you re right  so hilarious     1428217153   \n",
       "50   yeah  i ve contemplated that quite a bit as we...    1428217153   \n",
       "74                      let us plan this one              1428217153   \n",
       "107                                             which     1428217154   \n",
       "127        he s had a lot of reddit love today  but...    1428217154   \n",
       "155                         we already have the shoes     1428217154   \n",
       "166                                         cool  cool    1428217154   \n",
       "170  you do know he abandoned us  right   i mean  i...    1428217154   \n",
       "180  they don t consider you competent  you are sim...    1428217154   \n",
       "\n",
       "      parent_id controversiality   name score_hidden  distinguished archived  \\\n",
       "21     t3_7k903                0   t1_o        False            NaN     True   \n",
       "26   t1_c06vnj0                0   t1_t        False            NaN     True   \n",
       "50   t1_c06vwnq                0  t1_1h        False            NaN     True   \n",
       "74   t1_c06vwn9                0  t1_25        False            NaN     True   \n",
       "107    t3_7k7ff                0  t1_32        False            NaN     True   \n",
       "127    t3_7k7vs                0  t1_3m        False            NaN     True   \n",
       "155    t3_7k3z1                0  t1_4g        False            NaN     True   \n",
       "166    t3_7k90i                0  t1_4r        False            NaN     True   \n",
       "170  t1_c06vvdm                0  t1_4v        False            NaN     True   \n",
       "180    t3_7k377                0  t1_55        False            NaN     True   \n",
       "\n",
       "     created_utc removal_reason  \n",
       "21    1229580158            NaN  \n",
       "26    1229580220            NaN  \n",
       "50    1229580347            NaN  \n",
       "74    1229580422            NaN  \n",
       "107   1229580531            NaN  \n",
       "127   1229580640            NaN  \n",
       "155   1229580768            NaN  \n",
       "166   1229580821            NaN  \n",
       "170   1229580830            NaN  \n",
       "180   1229580843            NaN  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "remove_n = lambda x: re.sub(\"\\n\", \" \", x)\n",
    "\n",
    "# Remove all non-ascii characters \n",
    "remove_non_ascii = lambda x: re.sub(r'[^\\x00-\\x7f]',r' ', x)\n",
    "\n",
    "#remove_deleted = lambda x: re.sub('deleted','', x)\n",
    "\n",
    "# Apply all the lambda functions wrote previously through .map on the comments column\n",
    "ask_data['body'] = ask_data['body'].map(alphanumeric).map(punc_lower).map(remove_n).map(remove_non_ascii)\n",
    "\n",
    "ask_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_diagnostics(model, pr=True):\n",
    "#     \"\"\"\n",
    "#     Returns and prints the R-squared, RMSE and the MAE for a trained model\n",
    "#     \"\"\"\n",
    "#     y_predicted = model.predict(X_test)\n",
    "#     r2 = r2_score(y_test, y_predicted)\n",
    "#     mse = mean_squared_error(y_test, y_predicted)\n",
    "#     mae = mean_absolute_error(y_test, y_predicted)\n",
    "#     if pr:\n",
    "#         print(f\"R-Sq: {r2:.4}\")\n",
    "#         print(f\"RMSE: {np.sqrt(mse)}\")\n",
    "#         print(f\"MAE: {mae}\")\n",
    "    \n",
    "#     return [r2,np.sqrt(mse),mae]\n",
    "# def plot_residuals(y_test, y_predicted):\n",
    "#     \"\"\"\"\n",
    "#     Plots the distribution for actual and predicted values of the target variable. Also plots the distribution for the residuals\n",
    "#     \"\"\"\n",
    "#     fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, sharey=True)\n",
    "#     sns.distplot(y_test, ax=ax0, kde = False)\n",
    "#     ax0.set(xlabel='Test scores')\n",
    "#     sns.distplot(y_predicted, ax=ax1, kde = False)\n",
    "#     ax1.set(xlabel=\"Predicted scores\")\n",
    "#     plt.show()\n",
    "#     fig, ax2 = plt.subplots()\n",
    "#     sns.distplot((y_test-y_predicted), ax = ax2,kde = False)\n",
    "#     ax2.set(xlabel=\"Residuals\")\n",
    "#     plt.show()\n",
    "# def y_test_vs_y_predicted(y_test,y_predicted):\n",
    "#     \"\"\"\n",
    "#     Produces a scatter plot for the actual and predicted values of the target variable\n",
    "#     \"\"\"\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.scatter(y_test, y_predicted)\n",
    "#     ax.set_xlabel(\"Test Scores\")\n",
    "#     ax.set_ylim([-75, 1400])\n",
    "#     ax.set_ylabel(\"Predicted Scores\")\n",
    "#     plt.show()\n",
    "# def get_feature_importance(model):\n",
    "#     \"\"\"\n",
    "#     For fitted tree based models, get_feature_importance can be used to get the feature importance as a tidy output\n",
    "#     \"\"\"\n",
    "#     X_non_text = pd.get_dummies(df[cat_cols])\n",
    "#     features = numeric_cols + bool_cols + list(X_non_text.columns)\n",
    "#     feature_importance = dict(zip(features, model.feature_importances_))\n",
    "#     for name, importance in sorted(feature_importance.items(), key=lambda x: x[1], reverse=True):\n",
    "#         print(f\"{name:<30}: {importance:>6.2%}\")\n",
    "#         print(f\"\\nTotal importance: {sum(feature_importance.values()):.2%}\")\n",
    "#     return feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bool_cols = ['score_hidden', 'archived']\n",
    "\n",
    "# cat_cols = ['subreddit', 'subreddit_id', 'link_id']\n",
    "\n",
    "# numeric_cols = ['gilded', 'controversiality', 'downs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lb = LabelBinarizer()\n",
    "# cat = [lb.fit_transform(ask_data[col]) for col in cat_cols]\n",
    "# bol = [ask_data[col].astype('int') for col in bool_cols]\n",
    "# t = ask_data.loc[:, numeric_cols].values\n",
    "# final = [t] + bol + cat\n",
    "# y = ask_data.score.values\n",
    "# x = np.column_stack(tuple(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_performance_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for pre-processing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Import packages to split data and evaluate model performance\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, fbeta_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Import ML algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_tf_train_test(ask_data,score,vectorizer,ngram):\n",
    "\n",
    "# Train/Test split\n",
    "    X = ask_data.body\n",
    "    y = ask_data[score]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Count Vectorizer/TF-IDF\n",
    "    cv1 = vectorizer(ngram_range=(ngram), stop_words='english')\n",
    "    \n",
    "    X_train_cv1 = cv1.fit_transform(X_train)\n",
    "    X_test_cv1  = cv1.transform(X_test)\n",
    "         \n",
    "# Initialize all model objects and fit the models on the training data\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train_cv1, y_train)\n",
    "    print('lr done')\n",
    "\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X_train_cv1, y_train)\n",
    "    print('mnb done')\n",
    "    \n",
    "    svm_model = LinearSVC()\n",
    "    svm_model.fit(X_train_cv1, y_train)\n",
    "\n",
    "    f1_score_data = {'F1 Score':[f1_score(lr.predict(X_test_cv1), y_test, average='micro'), f1_score(mnb.predict(X_test_cv1), y_test, average='micro'),\n",
    "                                f1_score(svm_model.predict(X_test_cv1), y_test, average='micro')]} \n",
    "                          \n",
    "    df_f1 = pd.DataFrame(f1_score_data, index=['Log Regression', 'MultinomialNB', 'SVM'])  \n",
    "\n",
    "    return df_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr done\n",
      "mnb done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Score(toxic)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Log Regression</th>\n",
       "      <td>0.298691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.319598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.248212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                F1 Score(toxic)\n",
       "Log Regression         0.298691\n",
       "MultinomialNB          0.319598\n",
       "SVM                    0.248212"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tox_cv = cv_tf_train_test(ask_data, 'score', TfidfVectorizer, (1,1))\n",
    "df_tox_cv.rename(columns={'F1 Score': 'F1 Score(upvotes)'}, inplace=True)\n",
    "df_tox_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ok  here s what you do  get some speaker wire ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lol yeah you re right  so hilarious</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>yeah  i ve contemplated that quite a bit as we...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>let us plan this one</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>which</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>he s had a lot of reddit love today  but...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>we already have the shoes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>cool  cool</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>you do know he abandoned us  right   i mean  i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>they don t consider you competent  you are sim...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body  score\n",
       "21   ok  here s what you do  get some speaker wire ...      1\n",
       "26                lol yeah you re right  so hilarious       3\n",
       "50   yeah  i ve contemplated that quite a bit as we...      5\n",
       "74                      let us plan this one                1\n",
       "107                                             which       1\n",
       "127        he s had a lot of reddit love today  but...      4\n",
       "155                         we already have the shoes       1\n",
       "166                                         cool  cool     -1\n",
       "170  you do know he abandoned us  right   i mean  i...      3\n",
       "180  they don t consider you competent  you are sim...      2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_tox_done = pd.concat([ask_data['body'], ask_data['score']], axis=0)\n",
    "data_tox_done = ask_data.filter(['body','score'], axis=1)\n",
    "data_tox_done.shape\n",
    "data_tox_done.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data_tox_done.body\n",
    "y = data_tox_done['score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initiate a Tfidf vectorizer\n",
    "tfv = TfidfVectorizer(ngram_range=(1,1), stop_words='english')\n",
    "\n",
    "X_train_fit = tfv.fit_transform(X_train)\n",
    "X_test_fit = tfv.transform(X_test)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_fit, y_train)\n",
    "\n",
    "mnb.predict(X_test_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_model(data, label):\n",
    "    \n",
    "    X = data.body\n",
    "    y = data[label]\n",
    "\n",
    "    # Initiate a Tfidf vectorizer\n",
    "    tfv = TfidfVectorizer(ngram_range=(1,1), stop_words='english')\n",
    "\n",
    "    X_vect = tfv.fit_transform(X)  \n",
    "\n",
    "    with open(r\"{}.pkl\".format(label + '_vect'), \"wb\") as f:   \n",
    "        pickle.dump(tfv, f)   \n",
    "        \n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X_train_fit, y_train)\n",
    "\n",
    "    with open(r\"{}.pkl\".format(label + '_model'), \"wb\") as f:  \n",
    "        pickle.dump(mnb, f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = [data_tox_done]\n",
    "label = ['score']\n",
    "\n",
    "for i,j in zip(datalist,label):\n",
    "    pickle_model(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Sq: -6.123e-05\n",
      "RMSE: 13.048243614164234\n",
      "MAE: 4.832002002230764\n"
     ]
    }
   ],
   "source": [
    "# baseline = DummyRegressor(strategy='mean')\n",
    "# baseline.fit(X_train,y_train)\n",
    "# model_performance_dict[\"Baseline\"] = model_diagnostics(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Sq: -7.002e+24\n",
      "RMSE: 34525566084151.258\n",
      "MAE: 1045349751212.6859\n"
     ]
    }
   ],
   "source": [
    "# linear = LinearRegression()\n",
    "# linear.fit(X_train,y_train)\n",
    "# model_performance_dict[\"Linear Regression\"] = model_diagnostics(linear)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
